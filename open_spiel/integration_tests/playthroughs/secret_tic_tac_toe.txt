game: secret_tic_tac_toe

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Secret Tic Tac Toe"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = []
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "secret_tic_tac_toe"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 9
PolicyTensorShape() = [9]
MaxChanceOutcomes() = 0
GetParameters() = {}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [0]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 0
MaxGameLength() = 9
ToString() = "secret_tic_tac_toe()"

# State 0
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0) = []
ObservationTensor(1) = []
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 9, 1, 10, 2, 11, 3, 12, 4, 13, 5, 14, 6, 15, 7, 16, 8, 17]
StringLegalActions() = ["Action(id=0, player=0)", "Action(id=9, player=0)", "Action(id=1, player=0)", "Action(id=10, player=0)", "Action(id=2, player=0)", "Action(id=11, player=0)", "Action(id=3, player=0)", "Action(id=12, player=0)", "Action(id=4, player=0)", "Action(id=13, player=0)", "Action(id=5, player=0)", "Action(id=14, player=0)", "Action(id=6, player=0)", "Action(id=15, player=0)", "Action(id=7, player=0)", "Action(id=16, player=0)", "Action(id=8, player=0)", "Action(id=17, player=0)"]

# Apply action "Action(id=6, player=0)"
action: 6

# State 1
# 6.
IsTerminal() = False
History() = [6]
HistoryString() = "6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "6."
InformationStateString(1) = "6?"
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0) = []
ObservationTensor(1) = []
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 9, 1, 10, 2, 11, 3, 12, 4, 13, 5, 14, 6, 15, 7, 16, 8, 17]
StringLegalActions() = ["Action(id=0, player=1)", "Action(id=9, player=1)", "Action(id=1, player=1)", "Action(id=10, player=1)", "Action(id=2, player=1)", "Action(id=11, player=1)", "Action(id=3, player=1)", "Action(id=12, player=1)", "Action(id=4, player=1)", "Action(id=13, player=1)", "Action(id=5, player=1)", "Action(id=14, player=1)", "Action(id=6, player=1)", "Action(id=15, player=1)", "Action(id=7, player=1)", "Action(id=16, player=1)", "Action(id=8, player=1)", "Action(id=17, player=1)"]

# Apply action "Action(id=3, player=1)"
action: 3

# State 2
# 6., 3.
IsTerminal() = False
History() = [6, 3]
HistoryString() = "6, 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "6., 3?"
InformationStateString(1) = "6?, 3."
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0) = []
ObservationTensor(1) = []
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 9, 1, 10, 2, 11, 3, 12, 4, 13, 5, 14, 6, 15, 7, 16, 8, 17]
StringLegalActions() = ["Action(id=0, player=0)", "Action(id=9, player=0)", "Action(id=1, player=0)", "Action(id=10, player=0)", "Action(id=2, player=0)", "Action(id=11, player=0)", "Action(id=3, player=0)", "Action(id=12, player=0)", "Action(id=4, player=0)", "Action(id=13, player=0)", "Action(id=5, player=0)", "Action(id=14, player=0)", "Action(id=6, player=0)", "Action(id=15, player=0)", "Action(id=7, player=0)", "Action(id=16, player=0)", "Action(id=8, player=0)", "Action(id=17, player=0)"]

# Apply action "Action(id=9, player=0)"
action: 9

# State 3
# 6., 3., 0o
IsTerminal() = False
History() = [6, 3, 9]
HistoryString() = "6, 3, 9"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "6., 3?, 0o"
InformationStateString(1) = "6?, 3., 0?"
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0) = []
ObservationTensor(1) = []
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [1, 10, 2, 11, 3, 12, 4, 13, 5, 14, 6, 15, 7, 16, 8, 17]
StringLegalActions() = ["Action(id=1, player=1)", "Action(id=10, player=1)", "Action(id=2, player=1)", "Action(id=11, player=1)", "Action(id=3, player=1)", "Action(id=12, player=1)", "Action(id=4, player=1)", "Action(id=13, player=1)", "Action(id=5, player=1)", "Action(id=14, player=1)", "Action(id=6, player=1)", "Action(id=15, player=1)", "Action(id=7, player=1)", "Action(id=16, player=1)", "Action(id=8, player=1)", "Action(id=17, player=1)"]

# Apply action "Action(id=16, player=1)"
action: 16

# State 4
# 6., 3., 0o, 7o
IsTerminal() = False
History() = [6, 3, 9, 16]
HistoryString() = "6, 3, 9, 16"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "6., 3?, 0o, 7?"
InformationStateString(1) = "6?, 3., 0?, 7o"
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0) = []
ObservationTensor(1) = []
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [1, 10, 2, 11, 3, 12, 4, 13, 5, 14, 6, 15, 8, 17]
StringLegalActions() = ["Action(id=1, player=0)", "Action(id=10, player=0)", "Action(id=2, player=0)", "Action(id=11, player=0)", "Action(id=3, player=0)", "Action(id=12, player=0)", "Action(id=4, player=0)", "Action(id=13, player=0)", "Action(id=5, player=0)", "Action(id=14, player=0)", "Action(id=6, player=0)", "Action(id=15, player=0)", "Action(id=8, player=0)", "Action(id=17, player=0)"]

# Apply action "Action(id=5, player=0)"
action: 5

# State 5
# 6., 3., 0o, 7o, 5.
IsTerminal() = False
History() = [6, 3, 9, 16, 5]
HistoryString() = "6, 3, 9, 16, 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "6., 3?, 0o, 7?, 5."
InformationStateString(1) = "6?, 3., 0?, 7o, 5?"
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0) = []
ObservationTensor(1) = []
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [1, 10, 2, 11, 3, 12, 4, 13, 5, 14, 6, 15, 8, 17]
StringLegalActions() = ["Action(id=1, player=1)", "Action(id=10, player=1)", "Action(id=2, player=1)", "Action(id=11, player=1)", "Action(id=3, player=1)", "Action(id=12, player=1)", "Action(id=4, player=1)", "Action(id=13, player=1)", "Action(id=5, player=1)", "Action(id=14, player=1)", "Action(id=6, player=1)", "Action(id=15, player=1)", "Action(id=8, player=1)", "Action(id=17, player=1)"]

# Apply action "Action(id=6, player=1)"
action: 6

# State 6
# Apply action "Action(id=3, player=0)"
action: 3

# State 7
# Apply action "Action(id=10, player=1)"
action: 10

# State 8
# Apply action "Action(id=13, player=0)"
action: 13

# State 9
# 6., 3., 0o, 7o, 5., 6., 3., 1o, 4o
IsTerminal() = True
History() = [6, 3, 9, 16, 5, 6, 3, 10, 13]
HistoryString() = "6, 3, 9, 16, 5, 6, 3, 10, 13"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "6., 3?, 0o, 7?, 5., 6?, 3., 1?, 4o"
InformationStateString(1) = "6?, 3., 0?, 7o, 5?, 6., 3?, 1o, 4?"
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0) = []
ObservationTensor(1) = []
Rewards() = [1, -1]
Returns() = [1, -1]
